{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 10 00:33:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.59       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P8     4W /  N/A |    678MiB /  4096MiB |     14%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2500    C+G   ...ram Files\\LGHUB\\lghub.exe    N/A      |\n",
      "|    0   N/A  N/A      7908    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     10128    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11040    C+G   ...293.47\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12148    C+G   ...ll\\1.0.0.505\\LineCall.exe    N/A      |\n",
      "|    0   N/A  N/A     13292    C+G   ...txyewy\\MiniSearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13432    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15188    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     16316    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     16656    C+G   ...\\app-1.0.9005\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     17684    C+G   ...s\\Win64\\EpicWebHelper.exe    N/A      |\n",
      "|    0   N/A  N/A     18340    C+G   ...LINE\\bin\\current\\LINE.exe    N/A      |\n",
      "|    0   N/A  N/A     19644    C+G   ...qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 設定訓練及測試資料集和訓練參數"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,:,0], rgb[:,:,:,1], rgb[:,:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BIT_COUNT = 16\n",
    "iterations = 7  #攻擊次數\n",
    "alpha = 0.0001  #攻擊程度\n",
    "epsilon = 8.0 / 255  #攻擊範圍\n",
    "EPOCH = 50 #訓練EPOCH\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train = x_train[:1500]\n",
    "y_train = y_train[:1500]\n",
    "x_test = x_test[:1500]\n",
    "\n",
    "x_train = rgb2gray(x_train)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = rgb2gray(x_test)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "x_train = tf.image.resize(x_train, [28,28]).numpy()\n",
    "x_test = tf.image.resize(x_test, [28,28]).numpy()\n",
    "\n",
    "image_shape = (28, 28, 1)\n",
    "x_train = x_train.reshape((-1,) + image_shape)\n",
    "x_test = x_test.reshape((-1,) + image_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 設定資料擴增"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomRotation(0.02, fill_mode = 'constant'),\n",
    "    RandomZoom(.2, .2)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 設定訓練模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.0002, beta_1=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 16)          4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 144)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               74240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 17)                2193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,385\n",
      "Trainable params: 264,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((28, 28, 1))\n",
    "x = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), padding=\"same\", activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(BIT_COUNT+1, activation=\"softmax\")(x)\n",
    "decoder = Model(inputs=inputs, outputs=x)\n",
    "decoder.compile(optimizer=adam, loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "decoder.summary()\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(decoder, to_file='model.png', show_shapes=True,show_layer_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "#利用pgd的idea修改圖片 讓它生出我想要的label\n",
    "def pgd_attack_to_target(input_image, target_label, loss_object, model, epsilon, alpha, iterations):\n",
    "    x_adv = input_image  # 複製一個圖片 (不要動到原圖片)\n",
    "    for i in range(iterations):  # 做很多次\n",
    "        x_adv = tf.convert_to_tensor(x_adv)  # 將圖片轉成tensor\n",
    "        with tf.GradientTape() as tape:  #開始計算梯度\n",
    "            tape.watch(x_adv)  # 要計算的圖片是x_adv\n",
    "            prediction = model(x_adv)  #先做判斷(取得目前的結果)\n",
    "            loss = loss_object(target_label, prediction)  # 計算loss(距離target有多遠)\n",
    "        grad = tape.gradient(loss, x_adv)  # 計算梯度 (loss對x_adv的梯度，d_loss/d_x_adv)\n",
    "        x_adv_new  = x_adv - alpha * tf.sign(grad)  # 更新圖片(做梯度下降會讓預測結果接近我想要的label)\n",
    "        x_adv = tf.clip_by_value(x_adv_new , x_adv - epsilon, x_adv + epsilon)  # 限制圖片的範圍\n",
    "        x_adv = tf.clip_by_value(x_adv, 0, 1)  # 限制圖片的範圍(圖片要在0~1之間)\n",
    "        x_adv = x_adv.numpy()  # 將圖片轉成numpy\n",
    "    return x_adv  # 回傳攻擊後的圖片"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    dec_loss = losses[\"decoder\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dec_loss, label=\"decoder loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "list = np.array([ i for i in range(BIT_COUNT+1)])\n",
    "user_code = np.eye(BIT_COUNT+1)[list]\n",
    "print(user_code)  #生成onehot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 訓練模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 20s 11ms/step - loss: 0.2300 - categorical_accuracy: 0.0589\n",
      "epoch:0  decoder_loss:[0.22997891902923584]\n",
      "1594/1594 [==============================] - 17s 11ms/step - loss: 0.2243 - categorical_accuracy: 0.0592\n",
      "epoch:1  decoder_loss:[0.22425687313079834]\n",
      "1594/1594 [==============================] - 17s 11ms/step - loss: 0.2242 - categorical_accuracy: 0.0592\n",
      "epoch:2  decoder_loss:[0.22416521608829498]\n",
      "1594/1594 [==============================] - 17s 10ms/step - loss: 0.2241 - categorical_accuracy: 0.0596\n",
      "epoch:3  decoder_loss:[0.2241104692220688]\n",
      "1594/1594 [==============================] - 17s 11ms/step - loss: 0.2241 - categorical_accuracy: 0.0589\n",
      "epoch:4  decoder_loss:[0.2240578830242157]\n",
      "1594/1594 [==============================] - 17s 11ms/step - loss: 0.2240 - categorical_accuracy: 0.0601\n",
      "epoch:5  decoder_loss:[0.22399595379829407]\n",
      "1594/1594 [==============================] - 21s 13ms/step - loss: 0.2239 - categorical_accuracy: 0.0603\n",
      "epoch:6  decoder_loss:[0.22394219040870667]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1500,28,28,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReluGrad]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCH):\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m##第一步 調整圖片 讓decoder能正確讀取出user_code\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, BIT_COUNT\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 13\u001B[0m         x_train_adv[i] \u001B[38;5;241m=\u001B[39m \u001B[43mpgd_attack_to_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train_adv\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43muser_code\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mDATA_LENGTH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlosses\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCategoricalCrossentropy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m##第二步 data augmentation(旋轉，縮放....)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     x_train_adv_att \u001B[38;5;241m=\u001B[39m [data_augmentation(x_train_adv[i]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(BIT_COUNT\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)]\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mpgd_attack_to_target\u001B[1;34m(input_image, target_label, loss_object, model, epsilon, alpha, iterations)\u001B[0m\n\u001B[0;32m      8\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m model(x_adv)  \u001B[38;5;66;03m#先做判斷(取得目前的結果)\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_object(target_label, prediction)  \u001B[38;5;66;03m# 計算loss(距離target有多遠)\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m grad \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_adv\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 計算梯度 (loss對x_adv的梯度，d_loss/d_x_adv)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m x_adv_new  \u001B[38;5;241m=\u001B[39m x_adv \u001B[38;5;241m-\u001B[39m alpha \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39msign(grad)  \u001B[38;5;66;03m# 更新圖片(做梯度下降會讓預測結果接近我想要的label)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m x_adv \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mclip_by_value(x_adv_new , x_adv \u001B[38;5;241m-\u001B[39m epsilon, x_adv \u001B[38;5;241m+\u001B[39m epsilon)  \u001B[38;5;66;03m# 限制圖片的範圍\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1084\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_gradients \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1081\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x)\n\u001B[0;32m   1082\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mflatten(output_gradients)]\n\u001B[1;32m-> 1084\u001B[0m flat_grad \u001B[38;5;241m=\u001B[39m \u001B[43mimperative_grad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimperative_grad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_sources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1088\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1089\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_sources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1090\u001B[0m \u001B[43m    \u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munconnected_gradients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n\u001B[0;32m   1093\u001B[0m   \u001B[38;5;66;03m# Keep track of watched variables before setting tape to None\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_watched_variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape\u001B[38;5;241m.\u001B[39mwatched_variables()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71\u001B[0m, in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     69\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown value for unconnected_gradients: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m unconnected_gradients)\n\u001B[1;32m---> 71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeGradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:159\u001B[0m, in \u001B[0;36m_gradient_function\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    157\u001B[0m     gradient_name_scope \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m forward_pass_name_scope \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    158\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(gradient_name_scope):\n\u001B[1;32m--> 159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mout_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m grad_fn(mock_op, \u001B[38;5;241m*\u001B[39mout_grads)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:413\u001B[0m, in \u001B[0;36m_ReluGrad\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m    411\u001B[0m \u001B[38;5;129m@ops\u001B[39m\u001B[38;5;241m.\u001B[39mRegisterGradient(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRelu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ReluGrad\u001B[39m(op, grad):\n\u001B[1;32m--> 413\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_nn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:10723\u001B[0m, in \u001B[0;36mrelu_grad\u001B[1;34m(gradients, features, name)\u001B[0m\n\u001B[0;32m  10721\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m  10722\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m> 10723\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m  10724\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[0;32m  10725\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myEnv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7107\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7105\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7106\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7107\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: OOM when allocating tensor with shape[1500,28,28,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReluGrad]"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_LENGTH = len(x_train)\n",
    "\n",
    "# x_train_adv[0]是沒有攻擊的圖片\n",
    "x_train_adv = [x_train.copy() for _ in range(BIT_COUNT+1)]\n",
    "\n",
    "losses = {\"decoder\": []}\n",
    "\n",
    "#開始訓練\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    ##第一步 調整圖片 讓decoder能正確讀取出user_code\n",
    "    for i in range(1, BIT_COUNT+1):\n",
    "        x_train_adv[i] = pgd_attack_to_target(x_train_adv[i], [user_code[i]] * DATA_LENGTH,\n",
    "                                              tf.keras.losses.CategoricalCrossentropy(), decoder, epsilon,\n",
    "                                              alpha, iterations)\n",
    "\n",
    "    ##第二步 data augmentation(旋轉，縮放....)\n",
    "    x_train_adv_att = [data_augmentation(x_train_adv[i]) for i in range(BIT_COUNT+1)]\n",
    "\n",
    "    #第四步 訓練Decoder\n",
    "    decoder_x = np.concatenate((np.concatenate([x_train_adv[i] for i in range(BIT_COUNT+1)]),\n",
    "                                np.concatenate([x_train_adv_att[i] for i in range(BIT_COUNT+1)])))\n",
    "    decoder_y = np.concatenate((np.concatenate([[user_code[i]] * DATA_LENGTH for i in range(BIT_COUNT+1)]),\n",
    "                                np.concatenate([[user_code[i]] * DATA_LENGTH for i in range(BIT_COUNT+1)])))\n",
    "\n",
    "    decoder_loss = decoder.fit(decoder_x, decoder_y, epochs=1)\n",
    "\n",
    "    #紀錄loss\n",
    "    # losses[\"discriminator\"].append(discriminator_loss.history[\"loss\"])\n",
    "    losses[\"decoder\"].append(decoder_loss.history[\"loss\"])\n",
    "    print(\"epoch:{}  decoder_loss:{}\".format(epoch, decoder_loss.history[\"loss\"]))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# decoder.save('models/decoder_one_hot_4_bit_cifar_10_binary_crossentropy.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}