{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 設定訓練及測試資料集和訓練參數"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,:,0], rgb[:,:,:,1], rgb[:,:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BIT_COUNT = 16\n",
    "iterations = 7  #攻擊次數\n",
    "alpha = 0.0001  #攻擊程度\n",
    "epsilon = 8.0 / 255  #攻擊範圍\n",
    "EPOCH = 50 #訓練EPOCH\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train = x_train[:1500]\n",
    "y_train = y_train[:1500]\n",
    "x_test = x_test[:1500]\n",
    "\n",
    "x_train = rgb2gray(x_train)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = rgb2gray(x_test)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "x_train = tf.image.resize(x_train, [28,28]).numpy()\n",
    "x_test = tf.image.resize(x_test, [28,28]).numpy()\n",
    "\n",
    "image_shape = (28, 28, 1)\n",
    "x_train = x_train.reshape((-1,) + image_shape)\n",
    "x_test = x_test.reshape((-1,) + image_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 設定資料擴增"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomRotation(0.02, fill_mode = 'constant'),\n",
    "    RandomZoom(.2, .2)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 設定訓練模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.0002, beta_1=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = Input((28, 28, 1))\n",
    "x = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), padding=\"same\", activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(BIT_COUNT+1, activation=\"softmax\")(x)\n",
    "decoder = Model(inputs=inputs, outputs=x)\n",
    "decoder.compile(optimizer=adam, loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "decoder.summary()\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(decoder, to_file='model.png', show_shapes=True,show_layer_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#利用pgd的idea修改圖片 讓它生出我想要的label\n",
    "def pgd_attack_to_target(input_image, target_label, loss_object, model, epsilon, alpha, iterations):\n",
    "    x_adv = input_image  # 複製一個圖片 (不要動到原圖片)\n",
    "    for i in range(iterations):  # 做很多次\n",
    "        x_adv = tf.convert_to_tensor(x_adv)  # 將圖片轉成tensor\n",
    "        with tf.GradientTape() as tape:  #開始計算梯度\n",
    "            tape.watch(x_adv)  # 要計算的圖片是x_adv\n",
    "            prediction = model(x_adv)  #先做判斷(取得目前的結果)\n",
    "            loss = loss_object(target_label, prediction)  # 計算loss(距離target有多遠)\n",
    "        grad = tape.gradient(loss, x_adv)  # 計算梯度 (loss對x_adv的梯度，d_loss/d_x_adv)\n",
    "        x_adv_new  = x_adv - alpha * tf.sign(grad)  # 更新圖片(做梯度下降會讓預測結果接近我想要的label)\n",
    "        x_adv = tf.clip_by_value(x_adv_new , x_adv - epsilon, x_adv + epsilon)  # 限制圖片的範圍\n",
    "        x_adv = tf.clip_by_value(x_adv, 0, 1)  # 限制圖片的範圍(圖片要在0~1之間)\n",
    "        x_adv = x_adv.numpy()  # 將圖片轉成numpy\n",
    "    return x_adv  # 回傳攻擊後的圖片"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    dec_loss = losses[\"decoder\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dec_loss, label=\"decoder loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list = np.array([ i for i in range(BIT_COUNT+1)])\n",
    "user_code = np.eye(BIT_COUNT+1)[list]\n",
    "print(user_code)  #生成onehot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 訓練模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "DATA_LENGTH = len(x_train)\n",
    "\n",
    "# x_train_adv[0]是沒有攻擊的圖片\n",
    "x_train_adv = [x_train.copy() for _ in range(BIT_COUNT+1)]\n",
    "\n",
    "losses = {\"decoder\": []}\n",
    "\n",
    "#開始訓練\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    ##第一步 調整圖片 讓decoder能正確讀取出user_code\n",
    "    for i in range(1, BIT_COUNT+1):\n",
    "        x_train_adv[i] = pgd_attack_to_target(x_train_adv[i], [user_code[i]] * DATA_LENGTH,\n",
    "                                              tf.keras.losses.CategoricalCrossentropy(), decoder, epsilon,\n",
    "                                              alpha, iterations)\n",
    "\n",
    "    ##第二步 data augmentation(旋轉，縮放....)\n",
    "    x_train_adv_att = [data_augmentation(x_train_adv[i]) for i in range(BIT_COUNT+1)]\n",
    "\n",
    "    #第四步 訓練Decoder\n",
    "    decoder_x = np.concatenate((np.concatenate([x_train_adv[i] for i in range(BIT_COUNT+1)]),\n",
    "                                np.concatenate([x_train_adv_att[i] for i in range(BIT_COUNT+1)])))\n",
    "    decoder_y = np.concatenate((np.concatenate([[user_code[i]] * DATA_LENGTH for i in range(BIT_COUNT+1)]),\n",
    "                                np.concatenate([[user_code[i]] * DATA_LENGTH for i in range(BIT_COUNT+1)])))\n",
    "\n",
    "    decoder_loss = decoder.fit(decoder_x, decoder_y, epochs=1)\n",
    "\n",
    "    #紀錄loss\n",
    "    # losses[\"discriminator\"].append(discriminator_loss.history[\"loss\"])\n",
    "    losses[\"decoder\"].append(decoder_loss.history[\"loss\"])\n",
    "    print(\"epoch:{}  decoder_loss:{}\".format(epoch, decoder_loss.history[\"loss\"]))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# decoder.save('models/decoder_one_hot_4_bit_cifar_10_binary_crossentropy.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# decoder.save('models/decoder_one_hot_4_bit_cifar_10_binary_crossentropy.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}